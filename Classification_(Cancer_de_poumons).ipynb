{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3nefqaU9mStwKkn37EeCa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WafaSanaa/Computer_Vision/blob/main/Classification_(Cancer_de_poumons).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9QnMGU-wiRw",
        "outputId": "86857ef2-d27c-41ee-f983-a41d7c14d8dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qEKaZucBscVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE1VTRawxllm",
        "outputId": "cd0646cd-7f4f-4d11-f0b7-bd1968ded8ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E-M3aIJytA1",
        "outputId": "3445d9bd-8cb1-4c36-afd4-599a12b9e8d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJlZj_rBy_lb",
        "outputId": "1c502bf2-f6f2-4d4f-afb0-1ac4ee5a0679"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "1lF0BXcQzMBp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = (\"/content/drive/MyDrive/Full Pack IA/Module2: Deep Learning/Data \")"
      ],
      "metadata": {
        "id": "Z-JU1x170Rnk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path_str = '/content/drive/MyDrive/Full Pack IA/Module2: Deep Learning/Data/train'"
      ],
      "metadata": {
        "id": "FS4Z-0FK0U4y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_path_str = '/content/drive/MyDrive/Full Pack IA/Module2: Deep Learning/Data/valid'"
      ],
      "metadata": {
        "id": "aBIKH44u0cnx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path_str = '/content/drive/MyDrive/Full Pack IA/Module2: Deep Learning/Data/test'"
      ],
      "metadata": {
        "id": "1t52dRPS0frK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "test_classes = os.listdir(test_path_str)"
      ],
      "metadata": {
        "id": "MmDNWONz02TV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Pré-proccessing Data**"
      ],
      "metadata": {
        "id": "MYpD1A9i5FsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "#Conv2D: couche de convolution 2D pour extraire des caracteristiques des images\n",
        "#Dense : couche de cnx\n",
        "#MaxPooling2D : couche de sous echantillonage qui reduit les dimensions\n",
        "#Flatten : couche qui aplatit les données en entrées en un vecteur\n",
        "#BatchNormalization : couche qui normalise les activations de la couche précédente\n",
        "#Dropout : couche de régularisation pour prévenir le sur apprentissage\n",
        "from sklearn.utils import shuffle\n",
        "#fonction pour mélanger les ensembles de données"
      ],
      "metadata": {
        "id": "PxFgHURJ5LIo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "#to_categorical : fonction pour convertir des vecteurs de classes en matrices de classes binaires"
      ],
      "metadata": {
        "id": "cpwKTgS66DDx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# fonctions pour évaluer les modèles de classification"
      ],
      "metadata": {
        "id": "pSMrknPlsfU6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def du nombre de classe de sortie\n",
        "num_classes = 4"
      ],
      "metadata": {
        "id": "tyKV_8Fus2KP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "77onUHIj392E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
        "#configuration du générateur d'image pour l'entrainement avec augmentation de données\n",
        "trainGenerator = ImageDataGenerator(\n",
        "    preprocessing_function = preprocess_input , #prétraitement des image\n",
        "    rotation_range = 10,  # rotation aléatoire des images dans une plage de 10 degrés\n",
        "    width_shift_range = 0.3,  # translation horizontale aléatoire des images dans une plage de 30%\n",
        "    height_shift_range = 0.3,  # translation verticale aléatoire des images dans une plage de 30%\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    dtype = 'float32'\n",
        ")"
      ],
      "metadata": {
        "id": "0yQSY4RQtDkq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valGenerator = ImageDataGenerator(\n",
        "    preprocessing_function = preprocess_input,\n",
        "    dtype = 'float32'\n",
        ")"
      ],
      "metadata": {
        "id": "EdByXNYAuV69"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testGenerator = ImageDataGenerator(\n",
        "    preprocessing_function = preprocess_input,\n",
        "    dtype = 'float32'\n",
        ")"
      ],
      "metadata": {
        "id": "gwy9_E07xWxO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = trainGenerator.flow_from_directory(\n",
        "    train_path_str,                   # chemin du dossier contenant les images d'entraînement\n",
        "    target_size = (224, 224),         # taille des images en entrée du modèle\n",
        "    batch_size = 16,                  # nombre d’images par lot (batch)\n",
        "    class_mode = 'categorical'        # pour la classification multi-classes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ELv18kg0OT2",
        "outputId": "58449b32-4f34-4fb1-c174-11c222fafd4f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 613 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = valGenerator.flow_from_directory(\n",
        "    val_path_str,                     # chemin du dossier de validation\n",
        "    target_size = (224, 224),\n",
        "    batch_size = 16,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e67DDvT0hoT",
        "outputId": "4afe5bfe-af6f-4aa2-95ac-827facf64092"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 72 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = testGenerator.flow_from_directory(\n",
        "    test_path_str,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftVVjH4DCrdA",
        "outputId": "f31c982d-cdf3-4183-f565-9cf95d2b14b5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 315 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)\n",
        "VGG16_model = VGG16 (\n",
        "    include_top = False,\n",
        "    weights = \"imagenet\" ,\n",
        "    input_shape = input_shape\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqtsgh0tCuGL",
        "outputId": "666e9d60-1198-4f09-9692-3583e62ffe7d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in VGG16_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "uXBlWMlIDILY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Création de Modèle**"
      ],
      "metadata": {
        "id": "EfqIFRR_Eomd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import activations\n",
        "from tensorflow.keras.models import Sequential # Import Sequential from tensorflow.keras.models\n",
        "\n",
        "#création d'un modèle séquentiel\n",
        "model = Sequential()\n",
        "\n",
        "#Ajout du modèle vgg16 pré-entrainé sans la couche fully connected\n",
        "model.add(VGG16_model)\n",
        "\n",
        "# Ajout d'une couche de normalisation par lots pour améliorer la stabilité et la vitesse d'apprentissage\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Ajout d'une couche de pooling max pour réduire la dimensionnalité des données\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "# Aplatissement des données pour les préparer à l'entrée des couches Fully connected\n",
        "model.add(Flatten())\n",
        "\n",
        "# Première couche fully connected avec 1024 neurones activés par la fonction ReLU\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "# Dropout avec un taux de 30% pour prévenir le surapprentisage\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# deuxieme couche fully connected avec 1024 neurones activés par la fonction ReLU\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Dropout avec un taux de 50% pour prévenir le surapprentisage\n",
        "model.add(Dropout(0.5))\n",
        "\n"
      ],
      "metadata": {
        "id": "19tbjUPhEx_H"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}